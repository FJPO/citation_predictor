{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Internship_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMaTvqXdNPUsa9AxKKcnrzl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FJPO/citation_predictor/blob/main/Internship_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suk3DfUze-qS"
      },
      "source": [
        "PATH = input('Введите путь: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xxX1sL5oeC-"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from time import gmtime, strftime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f4ofRNBVCS-"
      },
      "source": [
        "# Здесь модель создается, обучается и тестируется\r\n",
        "def testNewModel(x_data, y_data):\r\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, train_size = 0.1)\r\n",
        "\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(200, input_dim = x_train.shape[1], activation = 'relu'))\r\n",
        "  model.add(Dense(200, activation = 'relu'))\r\n",
        "  model.add(Dense(200, activation = 'relu'))\r\n",
        "  model.add(Dropout(0.2))\r\n",
        "  model.add(Dense(1, activation = 'linear'))\r\n",
        "  model.compile(optimizer = Adam(lr = 0.001), loss = 'mae')\r\n",
        "\r\n",
        "  log = model.fit(x_train, y_train, 16, 40, verbose=0, validation_split = 0.1)\r\n",
        "\r\n",
        "  y_test_from_model = yScaler.inverse_transform(model.predict(x_test))\r\n",
        "  y_actual = yScaler.inverse_transform(y_test)\r\n",
        "\r\n",
        "  return {'log' : log,\r\n",
        "          'r2_score' : metrics.r2_score(y_test, model.predict(x_test)),\r\n",
        "          'model' : model\r\n",
        "          }\r\n",
        "\r\n",
        "# Метод для сохранения графика ошибки\r\n",
        "def saveLossPlot(result, descr):\r\n",
        "  if(descr == ''): descr = 'Plot'\r\n",
        "  # print('Точность:', result['r2_score'])\r\n",
        "  log = result['log']\r\n",
        "  plt.plot(log.history['loss'], label='Ошибка на обучающем наборе')\r\n",
        "  plt.plot(log.history['val_loss'], label='Ошибка на проверочном наборе')\r\n",
        "  plt.xlabel('Эпоха обучения')\r\n",
        "  plt.ylabel('Ошибка')\r\n",
        "  plt.legend()\r\n",
        "\r\n",
        "  plt.title(descr)\r\n",
        "  plt.savefig(strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) + '__' + descr + '.png')\r\n",
        "  # plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRPEDmvcfrhW"
      },
      "source": [
        "data = pd.read_csv(PATH)\r\n",
        "data = data.drop(['authors_mean_pagerank', 'authors_mean_productivity', 'journal_pagerank'], axis = 1)\r\n",
        "data = data[np.logical_and(~np.isnan(data).any(axis = 1), data['c5'] < 100)]\r\n",
        "\r\n",
        "\r\n",
        "# Предобработка данных\r\n",
        "yScaler = preprocessing.MinMaxScaler()\r\n",
        "y_data = yScaler.fit_transform(\r\n",
        "    np.array(data['c5']).reshape(-1,1)\r\n",
        "    )\r\n",
        "\r\n",
        "x_data = data.drop('c5', axis = 1)\r\n",
        "for i, name in enumerate(x_data.columns):\r\n",
        "    x_data[name] = preprocessing.MinMaxScaler().fit_transform(np.array(data[name]).reshape(-1, 1))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJawIN17fvxC"
      },
      "source": [
        "print('R^2 модели - ', testNewModel(x_data, y_data))\r\n",
        "print('Данный результат не является точным, для минимизации разброса заустите код из ячейки ниже')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GX1tLevpGMr"
      },
      "source": [
        "#\r\n",
        "#\r\n",
        "# Здесь вычисляется средняя и наибольшаяя точность работы модели\r\n",
        "# \r\n",
        "#\r\n",
        "results = []\r\n",
        "for i in range(50):\r\n",
        "  if(i%5 == 0): print(int(i/5), \"-\", sep = '', end = '')\r\n",
        "  model_result = testNewModel(x_data, y_data)\r\n",
        "  results.append(model_result['r2_score'])\r\n",
        "  if(model_result['r2_score'] > 0.55):\r\n",
        "    model_result['model'].save('r2_' + str(round(model_result['r2_score'], 3)) + '.h5')\r\n",
        "    saveLossPlot(model_result, 'r2_' + str(round(model_result['r2_score'], 3)))\r\n",
        "  \r\n",
        "print('\\nТочность в среднем:', np.array(results).mean())\r\n",
        "print('Точность в лучшем случае:', np.array(results).max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02GP8EinaSOX",
        "outputId": "55b8f8f6-fe5b-4d1e-e8f7-344bf06a91a5"
      },
      "source": [
        "# Код вычисляет зависимость работы модели от разных параметров\r\n",
        "\r\n",
        "for i, name in enumerate(x_data.columns):\r\n",
        "  results = []\r\n",
        "  for int in range(50):\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(40, input_dim = x_train.shape[1], activation = 'relu'))\r\n",
        "    model.add(Dense(40, activation = 'relu'))\r\n",
        "    model.add(Dense(1, activation = 'linear'))\r\n",
        "\r\n",
        "    model.compile(optimizer = Adam(lr = 0.001), loss = 'mae')\r\n",
        "\r\n",
        "    log = model.fit(x_train, y_train, 16, 20, verbose=0, validation_split = 0.1)\r\n",
        "    results.append(metrics.r2_score(y_test, model.predict(x_test)))\r\n",
        "  \r\n",
        "\r\n",
        "  print('\\nВ среднем случае для', name, ':\\t', np.array(results).mean())\r\n",
        "  print('В лучшем случае для', name, ':\\t', np.array(results).max())\r\n",
        "\r\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "В среднем случае для recency :\t 0.09454302118091251\n",
            "В лучшем случае для recency :\t 0.37379053139190144\n",
            "\n",
            "В среднем случае для topic_rank :\t 0.09096684243741607\n",
            "В лучшем случае для topic_rank :\t 0.36946172504362795\n",
            "\n",
            "В среднем случае для diversity :\t 0.11770783352169037\n",
            "В лучшем случае для diversity :\t 0.3737220721830494\n",
            "\n",
            "В среднем случае для authors_mean_rank :\t 0.06826653363483065\n",
            "В лучшем случае для authors_mean_rank :\t 0.3816612277779833\n",
            "\n",
            "В среднем случае для authors_mean_hindex :\t 0.08999349676235925\n",
            "В лучшем случае для authors_mean_hindex :\t 0.2901572128852693\n",
            "\n",
            "В среднем случае для authors_mean_gindex :\t 0.12432858358774192\n",
            "В лучшем случае для authors_mean_gindex :\t 0.3693337902446434\n",
            "\n",
            "В среднем случае для authors_mean_sociality :\t 0.093443662414163\n",
            "В лучшем случае для authors_mean_sociality :\t 0.32546686865706487\n",
            "\n",
            "В среднем случае для journal_rank :\t 0.05419405385924294\n",
            "В лучшем случае для journal_rank :\t 0.3073566772018187\n",
            "\n",
            "В среднем случае для title_len :\t 0.09284322321074417\n",
            "В лучшем случае для title_len :\t 0.38492187045532844\n",
            "\n",
            "В среднем случае для abstract_len :\t 0.09389279240715308\n",
            "В лучшем случае для abstract_len :\t 0.34657172102252887\n",
            "\n",
            "В среднем случае для n_authors :\t 0.07202929008371982\n",
            "В лучшем случае для n_authors :\t 0.3659752700110688\n",
            "\n",
            "В среднем случае для log_authors_mean_sociality :\t 0.10590960979885496\n",
            "В лучшем случае для log_authors_mean_sociality :\t 0.41020794051518983\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}